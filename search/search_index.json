{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Our mission","text":"<p>     The modern economy is built on complex digital systems like the cloud.     They are powerful, but painfully hard to operate.     AI agents promise automation, yet today they fail because they lack     operational intelligence:     an understanding of how engineered digital systems respond to actions.   </p> <p>     A simple truth:     the digital world has no physics,     but it obeys rules humans wrote down, which gives it meaning.     APIs, documentation, and traces precisely define how digital systems behave\u2014     what actions mean, what is allowed, and how failures arise.     The cloud is one such world, encoded by tens of thousands of APIs.   </p> <p> Our mission is to synthesize world models for digital systems using AI\u2014     and use them as training grounds to improve AI\u2019s execution intelligence,     starting with the cloud.   </p> <p>     \u2014 The Vera Team   </p>"},{"location":"about/","title":"About","text":"<p>This is the about page.</p>"},{"location":"vera-aws/","title":"Vera AWS (Version 0.1)","text":"<p>Local AWS EC2 emulator. Currently supports 89 resource types \u2014 VPCs, instances, security groups, volumes, and more (complete list at the end). Runs on your machine with no AWS account needed.</p>"},{"location":"vera-aws/#setup","title":"Setup","text":"<pre><code>./install.sh\n</code></pre> <p>This creates a venv, installs dependencies, sets up dummy AWS credentials (<code>~/.aws/credentials</code>), and generates two wrapper scripts in <code>.bin/</code>:</p> <ul> <li><code>awscli</code> \u2014 drop-in for <code>aws</code>, routes requests to the emulator</li> <li><code>terlocal</code> \u2014 drop-in for <code>terraform</code>, configures the AWS provider endpoint</li> </ul>"},{"location":"vera-aws/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>AWS CLI and Terraform are installed automatically by <code>install.sh</code> if missing (macOS/Linux)</li> </ul>"},{"location":"vera-aws/#usage","title":"Usage","text":"<p>Start the emulator on one terminal:</p> <pre><code>uv run main.py\n# Running at http://localhost:5003\n</code></pre>"},{"location":"vera-aws/#aws-cli-via-uv-run-awscli","title":"AWS CLI via <code>uv run awscli</code>","text":"<pre><code>uv run awscli ec2 create-vpc --cidr-block 10.0.0.0/16\n# {\n#     \"Vpc\": {\n#         \"VpcId\": \"vpc-28bc3a23\",\n#         \"CidrBlock\": \"10.0.0.0/16\",\n#         \"State\": \"available\",\n#         ...\n#     }\n# }\n</code></pre>"},{"location":"vera-aws/#aws-cli-directly-via-awscli","title":"AWS CLI directly via <code>awscli</code>","text":"<p>Simply activate the venv and run <code>awscli</code>:</p> <pre><code>source .venv/bin/activate\n\nawscli ec2 describe-vpcs\nawscli ec2 run-instances --image-id ami-12345678 --instance-type t2.micro\nawscli ec2 describe-instances\n</code></pre>"},{"location":"vera-aws/#terraform","title":"Terraform","text":"<p>Write standard Terraform \u2014 no provider overrides needed:</p> <pre><code>provider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n</code></pre> <p>Then use <code>uv run terlocal</code> instead of <code>terraform</code>. Or simply activate the venv and directly run <code>terlocal</code>:</p> <pre><code>source .venv/bin/activate\n\nterlocal init\nterlocal apply -auto-approve\nterlocal destroy -auto-approve\n</code></pre> <p>See <code>tests/tf/</code> for more examples.</p>"},{"location":"vera-aws/#running-tests","title":"Running Tests","text":"<pre><code># Terminal 1 \u2014 start the emulator\nuv run main.py\n\n# Terminal 2 \u2014 run 260 CLI commands against it\ncd tests\nuv run eval_emulator.py test.sh --endpoint http://localhost:5003 \\\n  --checkpoint eval_results.json --start-from 0\nuv run analyze_results.py eval_results.json\n\n# Terraform smoke test\ncd tests/tf/00-simple-vpc\nuv run terlocal init &amp;&amp; uv run terlocal apply -auto-approve\n</code></pre> Emulator Passing (260 commands) LocalStack 122 (47%) Vera AWS 187 (72%)"},{"location":"vera-aws/#project-structure","title":"Project Structure","text":"<pre><code>main.py                        Flask server (port 5003)\ninstall.sh                     Sets up awscli/terlocal wrappers\nemulator_core/\n\u251c\u2500\u2500 state.py                   In-memory resource store\n\u251c\u2500\u2500 backend.py                 Base backend class\n\u251c\u2500\u2500 gateway/base.py            Action \u2192 backend dispatch\n\u2514\u2500\u2500 services/                  89 resource modules\ntests/\n\u251c\u2500\u2500 test.sh                    260 CLI commands (awscli wrapper)\n\u251c\u2500\u2500 eval_emulator.py           Evaluator with checkpointing\n\u2514\u2500\u2500 tf/                        Terraform test cases\n</code></pre>"},{"location":"vera-aws/#supported-resources","title":"Supported Resources","text":"<p>Vera AWS supports the following resources (via EC2 API):</p> <ul> <li>Account Attributes</li> <li>AFIs</li> <li>AMIs</li> <li>Authorization Rules</li> <li>AWS Marketplace</li> <li>Block Public Access</li> <li>Bundle Tasks</li> <li>BYOASN</li> <li>BYOIP</li> <li>Capacity Reservations</li> <li>Carrier Gateways</li> <li>Certificate Revocation Lists</li> <li>Client Connections</li> <li>Client VPN Endpoints</li> <li>Configuration Files</li> <li>Customer Gateways</li> <li>Customer Owned IP Addresses</li> <li>Declarative Policies (Account Status Report)</li> <li>Dedicated Hosts</li> <li>DHCP Options</li> <li>EC2 Fleet</li> <li>EC2 Instance Connect Endpoints</li> <li>EC2 Topology</li> <li>Elastic Graphics</li> <li>Elastic IP Addresses</li> <li>Elastic Network Interfaces</li> <li>Encryption</li> <li>Event Notifications</li> <li>Event Windows For Scheduled Events</li> <li>Fast Snapshot Restores</li> <li>Infrastructure Performance</li> <li>Instance Types</li> <li>Instances</li> <li>Internet Gateways</li> <li>IPAMs</li> <li>Key Pairs</li> <li>Launch Templates</li> <li>Link Aggregation Groups</li> <li>Local Gateways</li> <li>Managed Prefix Lists</li> <li>NAT Gateways</li> <li>Network Access Analyzer</li> <li>Network ACLs</li> <li>Nitro TPM</li> <li>Placement Groups</li> <li>Pools</li> <li>Reachability Analyzer</li> <li>Regions And Zones</li> <li>Reserved Instances</li> <li>Resource Discoveries</li> <li>Resource IDs</li> <li>Route Servers</li> <li>Route Tables</li> <li>Routes</li> <li>Scheduled Instances</li> <li>Scopes</li> <li>Security Groups</li> <li>Serial Console</li> <li>Service Links</li> <li>Snapshots</li> <li>Spot Fleet</li> <li>Spot Instances</li> <li>Subnets</li> <li>Tags</li> <li>Target Networks</li> <li>Traffic Mirroring</li> <li>Transit Gateway Connect</li> <li>Transit Gateway Multicast</li> <li>Transit Gateway Peering Attachments</li> <li>Transit Gateway Policy Tables</li> <li>Transit Gateway Route Tables</li> <li>Transit Gateways</li> <li>Verified Access Endpoints</li> <li>Verified Access Groups</li> <li>Verified Access Instances</li> <li>Verified Access Logs</li> <li>Verified Access Trust Providers</li> <li>Virtual Private Gateway Routes</li> <li>Virtual Private Gateways</li> <li>VM Export</li> <li>VM Import</li> <li>Volumes</li> <li>VPC Endpoint Services</li> <li>VPC Endpoints</li> <li>VPC Flow Logs</li> <li>VPC Peering</li> <li>VPCs</li> <li>VPN Concentrators</li> <li>VPN Connections</li> </ul>"},{"location":"blogs/cloudagent/cloudagent/","title":"Can AI Agents Replace DevOps? What We Learned Trying to Replace DevOps with AI Agents","text":"February 6, 2026  <p>Cloud infrastructure is the cornerstone of the modern IT industry, yet managing it remains a surprisingly manual and tedious endeavor. From provisioning resources to debugging failures, DevOps teams are constantly battling complexity.</p> <p>In our recent paper, \"Cloud Infrastructure Management in the Age of AI Agents,\" my colleagues and I explore a provocative question: Is it time for AI agents to take the reins?</p> <p>We didn't just want to build a demo; we wanted to understand the fundamental friction between AI models and cloud interfaces. We envision a future where Large Language Models (LLMs) empower autonomous agents to handle these complex workflows. But to get there, we first had to break things.</p>"},{"location":"blogs/cloudagent/cloudagent/#the-setup-a-battle-of-four-agents","title":"The Setup: A Battle of Four Agents","text":"<p>To test the current capabilities of AI, we conducted a preliminary study using four different \"modalities\"\u2014the standard interfaces humans use to manage the cloud. We built four distinct AI agent prototypes to perform tasks on Microsoft Azure:</p> <ol> <li>SDK Agent: Uses Python code (imperative programming).</li> <li>CLI Agent: Uses command-line shell scripts (terminal-based).</li> <li>Infrastructure-as-Code (IaC) Agent: Uses Terraform (declarative configuration).</li> <li>ClickOps Agent: Navigates the web portal visually (just like a human clicking buttons).</li> </ol> <p> Figure 1: Four cloud user interaction modalities with simplified code snippets. </p>"},{"location":"blogs/cloudagent/cloudagent/#insight-1-speed-vs-visibility-the-blindness-of-code","title":"Insight 1: Speed vs. Visibility (The \"Blindness\" of Code)","text":"<p>We pitted these agents against each other in three rounds of tasks: Provisioning, Updates, and Monitoring. The results revealed a massive trade-off between execution speed and state awareness.</p> <p>The CLI agent was the speed demon of the group. For provisioning tasks, it was highly efficient, completing tasks in an average of 1.6 steps. Because it operates via text commands, it could often do in one line what took the ClickOps agent 30 times as many steps to achieve. The ClickOps agent was excruciatingly slow because it had to wait for page loads and navigate complex menus, just like a human user would.</p> <p>However, speed isn't everything. When we moved to Update tasks (like changing a VM's disk), the \"blindness\" of the coding agents became a liability. The CLI and SDK agents struggled because they couldn't easily \"see\" the current configuration of the cloud. They often failed because they needed to query the state before modifying it, introducing extra steps where errors could creep in.</p> <p>In contrast, the ClickOps agent actually performed better here (67% success rate vs. 33% for IaC). Why? Because the web portal visually presented the existing configuration. The agent could \"see\" the current state on the screen, reducing hallucinations and errors during modification.</p>"},{"location":"blogs/cloudagent/cloudagent/#insight-2-the-wrong-tool-fallacy","title":"Insight 2: The \"Wrong Tool\" Fallacy","text":"<p>One of our most critical findings was that some industry-standard tools are fundamentally ill-suited for AI agents in certain contexts.</p> <p>Take Infrastructure-as-Code (IaC). It is the gold standard for human DevOps because it is declarative\u2014you describe what you want, not how to get there. But for an AI agent trying to Monitor a system, IaC was a disaster.</p> <p>When we asked the IaC agent to check the health of a system, it failed significantly (40% success rate). IaC is designed to define infrastructure, not to query real-time telemetry. The agent hallucinated non-existent commands because it was trying to force a square peg into a round hole. Meanwhile, the Web/ClickOps agent excelled at monitoring because it could simply look at the graphs and dashboards already built into the Azure portal.</p> <p> Figure 2: The radar chart summarizing agent performance across different modalities. </p>"},{"location":"blogs/cloudagent/cloudagent/#the-path-forward-a-new-architecture","title":"The Path Forward: A New Architecture","text":"<p>Our experiments highlight that simply connecting an LLM to a cloud shell isn't enough. We need a more sophisticated architecture that embraces these trade-offs.</p> <p>We propose a new roadmap for Agentic Cloud Management involving three key pillars:</p> <ol> <li>Multi-Agent Orchestration: We shouldn't force one agent to do everything. We envision a system that routes tasks to the best \"expert.\" It would dispatch a CLI agent for fast provisioning but switch to a ClickOps agent for visual debugging or monitoring.</li> <li>Sandboxed Exploration (\"Cloud Gyms\"): Agents need a safe space to fail. We propose separating workflows into \"Exploration\" and \"Exploitation\" phases. Agents should test their strategies in a sandboxed \"gym\"\u2014a simulated or non-production environment\u2014before touching live infrastructure.</li> <li>Workflow Memory &amp; Guardrails: Once an agent figures out a complex task in the sandbox, it shouldn't have to relearn it. It should \"cache\" that workflow into a memory bank for future use. Furthermore, we need strict \"human-in-the-loop\" guardrails to prevent costly or dangerous mistakes before they happen.</li> </ol> <p> Figure 3: Envisioned agentic system architecture and workflow. </p>"},{"location":"blogs/cloudagent/cloudagent/#conclusion","title":"Conclusion","text":"<p>Cloud management is ripe for automation, but our research shows that the interface matters just as much as the model. By combining the speed of CLI, the stability of IaC, and the visibility of ClickOps, we can build the next generation of autonomous cloud engineers.</p> <p>For more details, check out our full paper in the ACM SIGOPS Operating Systems Review.</p> Authors:     Zhenning Yang, Archit Bhatnagar, Yiming Qiu, Tongyuan Miao, Patrick Tser Jern Kon, Yunming Xiao, Yibo Huang, Martin Casado, Ang Chen    Affiliations:     University of Michigan, UC Berkeley, Andreessen Horowitz    Paper link:        https://dl.acm.org/doi/abs/10.1145/3759441.3759443      BibTeX: <pre>\n<code>@article{yang2025cloudagent,\n    author = {Yang, Zhenning and Bhatnagar, Archit and Qiu, Yiming and Miao, Tongyuan and Tser Jern Kon, Patrick and Xiao, Yunming and Huang, Yibo and Casado, Martin and Chen, Ang},\n    title = {Cloud Infrastructure Management in the Age of AI Agents},\n    journal = {SIGOPS Oper. Syst. Rev.},\n    year = {2025}\n}</code></pre>"},{"location":"blogs/cloudemu/cloudemu/","title":"No More Manual Mocks: A Case for Learned Cloud Emulators","text":"February 6, 2026  <p>DevOps engineers face a constant dilemma: testing against the real cloud is expensive and slow, but testing locally requires emulators that often lack features or behave differently than the real thing.</p> <p>Existing emulators (like the popular LocalStack) rely on manual engineering. We observe that this is a Sisyphean task\u2014AWS alone has over 240 services, and human developers struggle to keep up with the constant stream of new APIs and updates. As a result, coverage is often spotty; for example, we found that existing tools cover only ~11% of the AWS Network Firewall APIs.</p> <p>In our paper \"A Case for Learned Cloud Emulators,\" we propose a paradigm shift: instead of hand-coding mocks, why not use Large Language Models (LLMs) to learn the emulation logic directly from cloud documentation?</p>"},{"location":"blogs/cloudemu/cloudemu/#the-learned-emulator-approach","title":"The \"Learned Emulator\" Approach","text":"<p>Simply asking an LLM to \"write a cloud emulator\" results in buggy, hallucinated code. To solve this, we introduce a neuro-symbolic workflow that constrains the AI using formal abstractions. We view each cloud resource not just as code, but as a formal State Machine (SM).</p> <p> Figure 1: The grammar for specifying an emulator. </p> <p>Our workflow consists of three key stages:</p> <ol> <li>Documentation Wrangling: We automatically scrape and index massive cloud documentation (like AWS PDFs), organizing it into resource-specific contexts to overcome LLM context window limits.</li> <li>State Machine (SM) Extraction: Instead of generating raw Python code immediately, we task the LLM with extracting a formal State Machine specification from the docs. This captures the resource's states (e.g., \"available,\" \"pending\") and valid transitions (API calls like <code>CreateVpc</code>), enforcing logic and dependencies that unstructured code generation misses.</li> <li>Automated Alignment: To ensure the emulator behaves exactly like the real cloud, we run traces against both our generated emulator and the actual cloud. We detect discrepancies (e.g., an error code mismatch) and feed them back to the LLM to patch the logic automatically.</li> </ol> <p> Figure 2: Our envisioned workflow. </p>"},{"location":"blogs/cloudemu/cloudemu/#preliminary-results","title":"Preliminary Results","text":"<p>We built a prototype and the results highlight significant advantages over current manual methods:</p> <ul> <li>Better Coverage: In our preliminary tests, we achieved 100% API coverage for the AWS Network Firewall service, compared to just 11% for the state-of-the-art manual emulator.</li> <li>Accuracy: By modeling resources as State Machines, we prevent common logic errors. As shown below, our SM-based approach maintains high accuracy during state updates, whereas a direct-to-code (D2C) LLM approach often fails completely (0% accuracy) because it loses track of resource dependencies.</li> </ul> <p> Figure 3: Accuracy of learned emulators across scenarios. </p> <p>We also used our extracted state machines to quantify the complexity of different cloud services, counting the number of state transitions inherent to services like EC2 versus DynamoDB.</p> <p> Figure 4: CDF of SM complexity across services. </p>"},{"location":"blogs/cloudemu/cloudemu/#the-future-a-cloud-gym","title":"The Future: A \"Cloud Gym\"","text":"<p>Beyond just testing, we believe this technology opens new doors. A high-fidelity, zero-cost emulator could serve as a \"Cloud Gym\"\u2014a training ground for AI agents to learn how to manage cloud infrastructure without the risk of racking up a massive bill.</p> <p>By turning static documentation into executable logic, we hope to finally solve the bottleneck of cloud development velocity.</p> <p>For more details, check out our full paper in the HotNets '25 proceedings.</p> Authors:     Archit Bhatnagar, Yiming Qiu, Sarah McClure, Sylvia Ratnasamy, Ang Chen    Affiliations:     University of Michigan, The University of Hong Kong, UC Berkeley    Paper link:        https://dl.acm.org/doi/10.1145/3772356.3772404      BibTeX: <pre>\n<code>@inproceedings{bhatnagar2025cloudemu,\n  author = {Bhatnagar, Archit and Qiu, Yiming and McClure, Sarah and Ratnasamy, Sylvia and Chen, Ang},\n  title = {A Case for Learned Cloud Emulators},\n  booktitle = {Proceedings of the 24th ACM Workshop on Hot Topics in Networks},\n  year = {2025}\n}</code></pre>"}]}